# Carta 48: C√≥digos Detectores y Correctores de Errores

> **Unidad 9**: Teor√≠a de la Informaci√≥n

---

## üéØ Pregunta

¬øQu√© son los c√≥digos detectores y correctores de errores? D√© ejemplos.

---

## üìù Respuesta Breve (de la carta original)

**C√≥digos de canal** agregan redundancia controlada para detectar/corregir errores de transmisi√≥n.

**C√≥digos Detectores**:
- Detectan errores pero no pueden corregirlos
- Ejemplo simple: **bit de paridad**
- Requieren retransmisi√≥n (ARQ)

**C√≥digos Correctores (FEC)**:
- Detectan Y corrigen errores sin retransmisi√≥n
- Requieren m√°s redundancia

**Ejemplos**:

*C√≥digos de bloque*:
- **Hamming (7,4)**: 4 bits datos, 3 bits paridad, corrige 1 error
- **Reed-Solomon**: muy usado (CD, DVD, QR, espacio)
- **BCH**: flexible, potente

*C√≥digos convolucionales*:
- **Viterbi decoding**: usado en telefon√≠a m√≥vil
- **Turbo codes**: cerca del l√≠mite de Shannon

**Par√°metro clave**: distancia de Hamming ‚Üí capacidad de detecci√≥n/correcci√≥n

---

## üìñ Explicaci√≥n Detallada

### üîç Introducci√≥n y Contexto

**¬øPor qu√© es importante este concepto?** Los c√≥digos detectores y correctores de errores son la raz√≥n por la cual las comunicaciones digitales modernas funcionan de manera confiable. Sin ellos, cada bit corrupto en una transmisi√≥n WiFi causar√≠a p√©rdida de datos, cada ray√≥n en un CD lo har√≠a inservible, y las comunicaciones espaciales ser√≠an imposibles. Estos c√≥digos transforman canales ruidosos e imperfectos en enlaces virtuales casi libres de errores.

**¬øD√≥nde se aplica?** La codificaci√≥n de canal est√° omnipresente en el mundo digital:
- **Almacenamiento**: Discos duros, SSDs, CDs, DVDs, Blu-ray utilizan Reed-Solomon
- **Comunicaciones m√≥viles**: 4G/5G emplean Turbo codes y LDPC
- **Internet**: TCP/IP usa checksums, WiFi emplea c√≥digos convolucionales
- **Espacio**: Voyager us√≥ c√≥digos concatenados, Mars rovers usan Turbo codes
- **C√≥digos QR**: Pueden recuperarse incluso con 30% de da√±o gracias a Reed-Solomon

**¬øCu√°ndo lo encontrar√°s?** Los c√≥digos de canal se aplican despu√©s de la codificaci√≥n de fuente pero antes de la modulaci√≥n. Son la √∫ltima l√≠nea de defensa digital antes de convertir los bits en se√±ales anal√≥gicas, y la primera protecci√≥n al recibir.

**Historia**: Richard Hamming desarroll√≥ los primeros c√≥digos correctores en 1950 mientras trabajaba en Bell Labs, frustrado porque las computadoras se deten√≠an por errores simples. Claude Shannon hab√≠a demostrado te√≥ricamente en 1948 que era posible la comunicaci√≥n libre de errores, pero Hamming fue el primero en mostrar c√≥mo hacerlo pr√°cticamente.

### üìê Fundamentos Te√≥ricos

#### Conceptos Prerequisitos
- **Distancia de Hamming**: n√∫mero de bits diferentes entre dos palabras
- **Espacio de c√≥digos**: conjunto de todas las palabras c√≥digo v√°lidas
- **Teorema de Shannon (Carta 45)**: establece que es posible comunicaci√≥n libre de errores

#### Desarrollo Paso a Paso

**Paso 1: El Problema Fundamental**

En cualquier canal real, los bits pueden corromperse por ruido, interferencia, o imperfecciones del medio. Si transmitimos "1011", podr√≠amos recibir "1001" (error en el tercer bit). Sin protecci√≥n, este error es indetectable e incorregible.

**Paso 2: La Soluci√≥n - Redundancia Controlada**

La idea clave es agregar bits extra (redundancia) de manera sistem√°tica. No cualquier redundancia sirve; debe seguir reglas matem√°ticas precisas que permitan:
1. Detectar cu√°ndo ocurri√≥ un error
2. Idealmente, determinar qu√© bit(s) se corrompieron
3. Corregir los errores autom√°ticamente

**Paso 3: Clasificaci√≥n de C√≥digos**

Los c√≥digos se clasifican seg√∫n su estructura y capacidad:

**Por estructura:**
- **C√≥digos de bloque**: procesan bloques fijos de k bits ‚Üí n bits (n > k)
- **C√≥digos convolucionales**: procesan flujo continuo con memoria

**Por capacidad:**
- **Solo detecci√≥n**: identifican errores pero requieren retransmisi√≥n
- **Correcci√≥n directa (FEC)**: corrigen errores sin retransmisi√≥n

#### Derivaci√≥n Matem√°tica

**Capacidad de detecci√≥n y correcci√≥n:**

Para un c√≥digo con distancia m√≠nima de Hamming $d_{min}$:

**Capacidad de detecci√≥n:**
$$e_d = d_{min} - 1$$

Un c√≥digo puede detectar hasta $e_d$ errores porque cualquier patr√≥n de error con ‚â§ $e_d$ bits no puede transformar una palabra c√≥digo v√°lida en otra v√°lida.

**Capacidad de correcci√≥n:**
$$e_c = \left\lfloor \frac{d_{min} - 1}{2} \right\rfloor$$

Para corregir, necesitamos que la palabra recibida est√© m√°s cerca de la palabra correcta que de cualquier otra palabra c√≥digo.

**Ejemplo - C√≥digo de Hamming (7,4):**

Matriz generadora:
$$G = \begin{pmatrix}
1 & 0 & 0 & 0 & 1 & 0 & 1 \\
0 & 1 & 0 & 0 & 1 & 1 & 0 \\
0 & 0 & 1 & 0 & 0 & 1 & 1 \\
0 & 0 & 0 & 1 & 1 & 1 & 1
\end{pmatrix}$$

Matriz de paridad:
$$H = \begin{pmatrix}
1 & 1 & 0 & 1 & 1 & 0 & 0 \\
0 & 1 & 1 & 1 & 0 & 1 & 0 \\
1 & 0 & 1 & 1 & 0 & 0 & 1
\end{pmatrix}$$

**S√≠ndrome para detecci√≥n/correcci√≥n:**
$$\boxed{s = H \cdot r^T}$$

donde $r$ es la palabra recibida. Si $s = 0$, no hay error. Si $s ‚â† 0$, el s√≠ndrome indica la posici√≥n del error.

### üî¨ Intuici√≥n y Analog√≠as

**Analog√≠a principal:**

Imagina enviar un paquete fr√°gil por correo. El c√≥digo detector es como el n√∫mero de seguimiento - te dice si lleg√≥ correctamente pero no puede reparar da√±os. El c√≥digo corrector es como embalar el objeto con espuma protectora y piezas de repuesto - el paquete puede autorrepararse de da√±os menores.

**Intuici√≥n f√≠sica:**

Los c√≥digos correctores funcionan creando "esferas" de palabras c√≥digo en el espacio de Hamming. Si una palabra se corrompe ligeramente, todav√≠a cae dentro de la esfera de la palabra original, permitiendo la correcci√≥n. Es como tener tolerancias en ingenier√≠a mec√°nica.

**Visualizaci√≥n:**

En un espacio de 3 bits, tenemos 8 posibles palabras (000 a 111). Si solo usamos 2 como palabras c√≥digo v√°lidas (000 y 111), tienen distancia 3. Cualquier error simple nos deja m√°s cerca de la palabra original:
- 000 con 1 error ‚Üí 001, 010, o 100 (todas m√°s cerca de 000)
- 111 con 1 error ‚Üí 110, 101, o 011 (todas m√°s cerca de 111)

### üí° Ejemplos Pr√°cticos

#### Ejemplo 1: Bit de Paridad Simple

**Situaci√≥n:** Transmitir el byte 10110011 con protecci√≥n b√°sica.

**Datos:**
| Par√°metro | Valor | Descripci√≥n |
|-----------|-------|-------------|
| Datos originales | 10110011 | 8 bits |
| Tipo de paridad | Par | N√∫mero par de 1s |
| Bits de 1s | 5 | Impar |

**Soluci√≥n paso a paso:**

1. **Contar 1s en datos originales:**
   $$\text{N√∫mero de 1s} = 5 \text{ (impar)}$$

2. **Calcular bit de paridad:**
   $$\text{Bit de paridad} = 1 \text{ (para hacer el total par)}$$

3. **Palabra transmitida:**
   $$\boxed{101100111 \text{ (9 bits)}}$$

**Detecci√≥n:** Si se recibe 101100101 (error en bit 7), la paridad es impar ‚Üí error detectado (pero no sabemos d√≥nde).

---

#### Ejemplo 2: C√≥digo de Hamming (7,4) en Acci√≥n

**Contexto:** Transmitir 1011 usando Hamming (7,4).

**Codificaci√≥n:**
| Bit de datos | d1 | d2 | d3 | d4 |
|--------------|----|----|----|----|
| Valor | 1 | 0 | 1 | 1 |

**C√°lculo de bits de paridad:**
- p1 = d1 ‚äï d2 ‚äï d4 = 1 ‚äï 0 ‚äï 1 = 0
- p2 = d1 ‚äï d3 ‚äï d4 = 1 ‚äï 1 ‚äï 1 = 1
- p3 = d2 ‚äï d3 ‚äï d4 = 0 ‚äï 1 ‚äï 1 = 0

**Palabra c√≥digo:** 1011010

**Simulaci√≥n de error:** Se recibe 1011110 (error en bit 5)
- S√≠ndrome: s = [1, 0, 1] = 5 en binario
- **Correcci√≥n:** Flip bit 5 ‚Üí 1011010 ‚úì

---

#### Ejemplo 3: Reed-Solomon en un CD de Audio

**Contexto:** Un CD usa Reed-Solomon RS(255,223) con s√≠mbolos de 8 bits.

**Par√°metros:**
- 223 s√≠mbolos de datos
- 32 s√≠mbolos de paridad
- Puede corregir hasta 16 s√≠mbolos err√≥neos

**¬øQu√© pasa cuando hay un ray√≥n?**

Si un ray√≥n da√±a 2mm del CD:
- A 1.2 m/s de velocidad lineal = 1.67 ms de datos perdidos
- A 44.1 kHz √ó 16 bits √ó 2 canales = 2,940 bits afectados
- Equivale a ~368 bytes = 368 s√≠mbolos

Sin correcci√≥n: p√©rdida total de audio
Con RS + interleaving: los 368 s√≠mbolos se dispersan en m√∫ltiples bloques, cada uno con ‚â§16 errores ‚Üí **recuperaci√≥n perfecta**

### üîó Conexiones con Otros Conceptos

#### Conceptos Relacionados (del mismo curso)
- **Teorema de Shannon** (Carta 45): Establece que existe codificaci√≥n para R < C
- **BER y Eb/N0** (Carta 31): Los c√≥digos mejoran BER para mismo Eb/N0
- **Modulaci√≥n digital** (Cartas 27-32): Se combina con FEC para sistemas robustos

#### Dependencias (lo que necesitas saber primero)
1. **√Ålgebra lineal**: Operaciones con matrices para c√≥digos de bloque
2. **Campos finitos (Galois)**: Base matem√°tica de Reed-Solomon
3. **Teor√≠a de probabilidad**: Para analizar rendimiento

#### Aplicaciones Posteriores (d√≥nde usar√°s esto)
1. **Sistemas de comunicaci√≥n modernos**: Todos usan FEC
2. **Almacenamiento confiable**: RAID, sistemas distribuidos
3. **Computaci√≥n cu√°ntica**: C√≥digos cu√°nticos correctores

### üéì Perspectiva de Examen

#### Lo que el profesor busca que entiendas
- La diferencia fundamental entre detecci√≥n y correcci√≥n
- C√≥mo la distancia de Hamming determina la capacidad del c√≥digo
- El trade-off entre redundancia y capacidad de correcci√≥n
- Por qu√© los c√≥digos son esenciales para alcanzar la capacidad de Shannon

#### Tipos de problemas t√≠picos
1. **Calcular capacidad de detecci√≥n/correcci√≥n**: Dado $d_{min}$, hallar $e_d$ y $e_c$
   - Estrategia: Aplicar f√≥rmulas $e_d = d_{min} - 1$, $e_c = \lfloor(d_{min} - 1)/2\rfloor$

2. **Codificar/decodificar con Hamming**: Aplicar matrices G y H
   - Estrategia: Multiplicaci√≥n matricial, interpretaci√≥n de s√≠ndrome

3. **An√°lisis de rendimiento**: Calcular probabilidad de error residual
   - Estrategia: Usar distribuci√≥n binomial para probabilidad de > $e_c$ errores

### ‚ö†Ô∏è Errores Comunes y Trampas

‚ùå **Error #1: Confundir tasa del c√≥digo con eficiencia**
- Por qu√© ocurre: R = k/n parece eficiencia pero es solo la fracci√≥n de bits √∫tiles
- C√≥mo evitarlo: Eficiencia real incluye ganancia de codificaci√≥n y mejora en BER
- Ejemplo: Un c√≥digo con R = 0.5 puede ser muy eficiente si permite usar modulaci√≥n de alto orden

‚ùå **Error #2: Pensar que m√°s redundancia siempre es mejor**
- Por qu√© ocurre: Intuitivamente parece que m√°s protecci√≥n = mejor
- C√≥mo evitarlo: Existe un √≥ptimo. Demasiada redundancia reduce la tasa efectiva
- L√≠mite: Shannon dice que existe un c√≥digo √≥ptimo para cada canal

‚ùå **Error #3: Ignorar la latencia en c√≥digos convolucionales**
- Distinci√≥n importante: C√≥digos de bloque procesan inmediatamente, convolucionales tienen memoria
- Impacto: En aplicaciones de tiempo real, la latencia puede ser cr√≠tica

### ‚úÖ Puntos Clave para Recordar

#### F√≥rmulas Esenciales
```
Detecci√≥n: e_d = d_min - 1
Correcci√≥n: e_c = ‚åä(d_min - 1)/2‚åã
Tasa del c√≥digo: R = k/n
L√≠mite de Singleton: d_min ‚â§ n - k + 1
```

#### Conceptos Fundamentales
- ‚úì **Distancia m√≠nima es clave**: Determina toda la capacidad del c√≥digo
- ‚úì **Trade-off fundamental**: Tasa vs. capacidad de correcci√≥n
- ‚úì **FEC vs. ARQ**: Forward Error Correction vs. Automatic Repeat Request
- ‚úì **L√≠mite de Shannon alcanzable**: Turbo y LDPC se acercan al l√≠mite te√≥rico

#### Reglas Mnemot√©cnicas
- üß† **"DCC"**: Distancia determina Capacidad de Correcci√≥n
- üß† **Hamming (7,4)**: "7 total, 4 datos, 3 paridad, 1 error corregible"

#### Valores T√≠picos (para referencias r√°pidas)
| Sistema | C√≥digo | Capacidad | Overhead |
|---------|--------|-----------|----------|
| WiFi 802.11 | Convolucional | BER 10^-5 ‚Üí 10^-10 | 50-75% |
| 4G LTE | Turbo | Cerca de Shannon | Variable |
| DVD | Reed-Solomon | Corrige r√°fagas | 13% |
| QR Code | RS + estructura | Hasta 30% da√±o | 7-30% |

### üìö Para Profundizar

#### Recursos Recomendados
- **Libros**: Lin & Costello "Error Control Coding" - La biblia del tema
- **Papers**: Berrou et al. (1993) sobre Turbo codes - Revolucionario
- **Simulaci√≥n**: GNU Radio tiene bloques FEC para experimentar

#### Temas Relacionados para Explorar
1. **C√≥digos LDPC**: Low-Density Parity Check - Usados en 5G
2. **C√≥digos polares**: Los m√°s recientes, probadamente √≥ptimos
3. **C√≥digos fuente**: LT codes, Raptor codes para erasure channels

#### Preguntas para Reflexionar
- ¬øPor qu√© los Turbo codes fueron tan revolucionarios cuando aparecieron en 1993?
- ¬øC√≥mo se puede demostrar que un c√≥digo alcanza la capacidad del canal?
- ¬øQu√© tipo de c√≥digo ser√≠a √≥ptimo para comunicaciones con Marte?

---

## üè∑Ô∏è Metadatos de la Carta

**Dificultad**: ‚≠ê‚≠ê‚≠ê‚≠ê (4/5 estrellas)
**Tiempo de estudio sugerido**: 50 minutos
**Prerequisitos cr√≠ticos**: √Ålgebra lineal, probabilidad, teor√≠a de Shannon
**Tags**: `#codigos-canal` `#FEC` `#hamming` `#reed-solomon` `#correccion-errores`

---

*Generado el: 2024-11-16*
*√öltima revisi√≥n: 2024-11-16*