# Carta 45: Teorema de Shannon-Hartley

> **Unidad 9**: Teor√≠a de la Informaci√≥n

---

## üéØ Pregunta

Enuncie y explique el Teorema de Shannon-Hartley.

---

## üìù Respuesta Breve (de la carta original)

El **Teorema de Shannon-Hartley** establece la **capacidad m√°xima** de un canal con ruido gaussiano blanco:

$$C = B \log_2\left(1 + \frac{S}{N}\right) \text{ bits/s}$$

donde:
- C = capacidad del canal (bits/s)
- B = ancho de banda (Hz)
- S/N = relaci√≥n se√±al a ruido (lineal)

**Implicaciones fundamentales**:
1. **L√≠mite te√≥rico**: tasa m√°xima para comunicaci√≥n libre de errores
2. **Trade-off BW-SNR**: se puede intercambiar ancho de banda por potencia y viceversa
3. **Inalcanzable en pr√°ctica**: pero indica direcci√≥n de dise√±o
4. **Base de comparaci√≥n**: eficiencia de sistemas reales vs. l√≠mite de Shannon

**Conclusi√≥n**: fija l√≠mite fundamental de lo que es posible en comunicaciones.

---

## üìñ Explicaci√≥n Detallada

### üîç Introducci√≥n y Contexto

El Teorema de Shannon-Hartley, publicado independientemente por Claude Shannon (1948) y Ralph Hartley (1928), es posiblemente el resultado m√°s importante en teor√≠a de comunicaciones. Este teorema establece el l√≠mite fundamental e insuperable de la velocidad a la que podemos transmitir informaci√≥n a trav√©s de cualquier canal de comunicaci√≥n con ruido.

**¬øPor qu√© es importante este concepto?** Antes de Shannon, los ingenieros cre√≠an que para transmitir sin errores necesitaban aumentar indefinidamente la potencia o reducir dr√°sticamente la velocidad. Shannon demostr√≥ algo revolucionario: existe una velocidad m√°xima espec√≠fica (la capacidad) por debajo de la cual podemos transmitir con error arbitrariamente peque√±o, y por encima de la cual el error es inevitable, sin importar cu√°nta potencia usemos.

**¬øD√≥nde se aplica?** El teorema es fundamental en:
- **Dise√±o de modems**: DSL, cable, fibra √≥ptica
- **Comunicaciones inal√°mbricas**: WiFi, 4G/5G, satelital
- **Almacenamiento**: discos duros, SSD (canal con ruido)
- **Est√°ndares modernos**: todos buscan acercarse al l√≠mite de Shannon

**¬øCu√°ndo lo encontrar√°s?** En cada decisi√≥n de dise√±o de sistemas: selecci√≥n de modulaci√≥n, codificaci√≥n, asignaci√≥n de potencia, y evaluaci√≥n de desempe√±o. Los sistemas modernos operan a 1-3 dB del l√≠mite de Shannon.

### üìê Fundamentos Te√≥ricos

#### Conceptos Prerequisitos
- Entrop√≠a y informaci√≥n mutua (Carta 44)
- Proceso gaussiano y ruido blanco
- Teor√≠a de probabilidad y procesos estoc√°sticos
- Concepto de canal de comunicaci√≥n

#### Desarrollo Paso a Paso

**Paso 1: Modelo del canal AWGN**

Consideramos el canal de ruido aditivo gaussiano blanco (AWGN):
$$Y = X + N$$

donde:
- X: se√±al transmitida con potencia S
- N: ruido gaussiano con potencia N
- Y: se√±al recibida

**Paso 2: Informaci√≥n mutua**

La capacidad es la m√°xima informaci√≥n mutua entre entrada y salida:
$$C = \max_{p(x)} I(X;Y)$$

Para el canal gaussiano, la distribuci√≥n √≥ptima de entrada es gaussiana.

**Paso 3: Derivaci√≥n de la capacidad**

Para entrada gaussiana y canal AWGN:
$$I(X;Y) = H(Y) - H(Y|X) = H(Y) - H(N)$$

donde:
- $H(Y)$: entrop√≠a de la salida (gaussiana con potencia S+N)
- $H(N)$: entrop√≠a del ruido (gaussiana con potencia N)

#### Derivaci√≥n Matem√°tica Completa

**Partiendo de la entrop√≠a diferencial gaussiana:**

Para una variable gaussiana con varianza $\sigma^2$:
$$h(X) = \frac{1}{2}\log_2(2\pi e \sigma^2)$$

**Aplicando al canal:**

La salida Y es gaussiana con potencia (S+N):
$$h(Y) = \frac{1}{2}\log_2[2\pi e(S+N)]$$

El ruido N es gaussiano con potencia N:
$$h(N) = \frac{1}{2}\log_2(2\pi eN)$$

**Calculando la informaci√≥n mutua:**
$$I(X;Y) = h(Y) - h(N) = \frac{1}{2}\log_2\left(\frac{S+N}{N}\right) = \frac{1}{2}\log_2\left(1 + \frac{S}{N}\right)$$

**Considerando el ancho de banda B:**

En tiempo continuo con ancho de banda B Hz, por el teorema del muestreo podemos transmitir 2B muestras/segundo independientes:

$$\boxed{C = B\log_2\left(1 + \frac{S}{N}\right) \text{ bits/s}}$$

**Significado f√≠sico de cada t√©rmino:**
- $B$: Ancho de banda disponible (Hz) - dimensi√≥n "espacial" del canal
- $S/N$: Calidad del canal - cu√°nto destaca la se√±al sobre el ruido
- $\log_2(1 + S/N)$: Bits por uso del canal (por dimensi√≥n)

### üî¨ Intuici√≥n y Analog√≠as

**Analog√≠a principal:**
Imagina una autopista (canal) con neblina (ruido):
- El ancho de banda B es como el n√∫mero de carriles
- La SNR es como la visibilidad a trav√©s de la neblina
- La capacidad C es el flujo m√°ximo de veh√≠culos sin accidentes
- M√°s carriles O mejor visibilidad aumentan el flujo
- Pero hay rendimientos decrecientes (logaritmo)

**Intuici√≥n f√≠sica:**
El teorema captura dos recursos fundamentales:
1. **Grados de libertad** (ancho de banda): m√°s dimensiones independientes para transmitir
2. **Distinguibilidad** (SNR): capacidad de diferenciar niveles de se√±al

**Visualizaci√≥n:**
La funci√≥n $\log_2(1 + SNR)$ tiene forma caracter√≠stica:
- SNR baja: crecimiento casi lineal (r√©gimen limitado por potencia)
- SNR alta: crecimiento logar√≠tmico lento (r√©gimen limitado por banda)
- Punto de inflexi√≥n alrededor de SNR = 1 (0 dB)

### üí° Ejemplos Pr√°cticos

#### Ejemplo 1: Canal de Voz Telef√≥nica

**Situaci√≥n:** L√≠nea telef√≥nica tradicional

**Datos:**
| Par√°metro | Valor | Unidades |
|-----------|-------|----------|
| Ancho de banda | 3100 | Hz |
| SNR | 30 | dB (1000 lineal) |

**Soluci√≥n paso a paso:**

1. **Convertir SNR a lineal:**
   $$SNR_{lineal} = 10^{30/10} = 1000$$

2. **Aplicar Shannon-Hartley:**
   $$C = 3100 \times \log_2(1 + 1000)$$
   $$C = 3100 \times 9.97$$

3. **Resultado:**
   $$\boxed{C = 30,900 \text{ bits/s}}$$

**Interpretaci√≥n:** El l√≠mite te√≥rico es ~31 kbps, explicando por qu√© los modems de 56k necesitaban trucos especiales y nunca alcanzaban velocidad nominal.

---

#### Ejemplo 2: WiFi 802.11ac

**Contexto:** Canal WiFi moderno de 80 MHz con buena se√±al

**Par√°metros reales:**
| Par√°metro | Valor | Notas |
|-----------|-------|-------|
| Ancho de banda | 80 MHz | Canal ancho |
| SNR t√≠pica | 40 dB | Excelente se√±al |
| SNR lineal | 10,000 | - |

**C√°lculo de capacidad te√≥rica:**
$$C = 80 \times 10^6 \times \log_2(1 + 10000)$$
$$C = 80 \times 10^6 \times 13.29$$
$$C = 1,063 \text{ Mbps}$$

**Realidad pr√°ctica:**
- 802.11ac alcanza ~867 Mbps (con 256-QAM, codificaci√≥n 5/6)
- Eficiencia: 867/1063 = 81.6% del l√≠mite de Shannon
- Overhead por: pre√°mbulos, pilotos, guard intervals, CSMA/CA

---

#### Ejemplo 3: Reg√≠menes L√≠mite

**¬øQu√© pasa cuando...?**

**Caso 1: SNR ‚Üí ‚àû (R√©gimen limitado por banda)**
$$C \approx B\log_2(SNR) \quad \text{(crecimiento logar√≠tmico)}$$

Duplicar la potencia solo agrega 1 bit/s/Hz adicional.

**Caso 2: SNR ‚Üí 0 (R√©gimen limitado por potencia)**
Usando aproximaci√≥n $\ln(1+x) \approx x$ para x peque√±o:
$$C \approx B \cdot \frac{S}{N} \cdot \frac{1}{\ln(2)} = 1.44 \cdot B \cdot \frac{S}{N}$$

La capacidad es proporcional a la potencia.

**Caso 3: Ancho de banda infinito**
$$C_{\infty} = \lim_{B‚Üí‚àû} B\log_2\left(1 + \frac{S}{N_0 B}\right) = \frac{S}{N_0 \ln(2)} = 1.44 \frac{S}{N_0}$$

Existe un l√≠mite finito incluso con banda infinita!

### üîó Conexiones con Otros Conceptos

#### Conceptos Relacionados (del mismo curso)
- **Entrop√≠a** (Carta 44): Capacidad maximiza la informaci√≥n mutua
- **Eb/N0 m√≠nimo** (Carta 57): L√≠mite de Shannon -1.59 dB
- **Modulaci√≥n adaptativa**: Ajusta esquema seg√∫n SNR disponible
- **C√≥digos correctores** (Carta 48): Permiten acercarse a C

#### Dependencias
1. Teor√≠a de informaci√≥n b√°sica ‚Üí necesaria para entender informaci√≥n mutua
2. Procesos aleatorios ‚Üí para caracterizar se√±al y ruido
3. Teor√≠a de muestreo ‚Üí relaciona tiempo continuo con discreto

#### Aplicaciones Posteriores
1. **Dise√±o de c√≥digos**: Turbo codes, LDPC se acercan al l√≠mite
2. **MIMO**: Extiende Shannon a m√∫ltiples antenas
3. **5G/6G**: Opera cerca del l√≠mite en cada subportadora

### üéì Perspectiva de Examen

#### Lo que el profesor busca que entiendas
- Shannon NO dice C√ìMO alcanzar la capacidad, solo que EXISTE
- El teorema asume codificaci√≥n de longitud infinita (no pr√°ctica)
- Trade-off fundamental: puedes intercambiar BW por SNR
- La capacidad es un l√≠mite superior estricto e infranqueable

#### Tipos de problemas t√≠picos
1. **C√°lculo directo**: Dados B y SNR, calcular C
2. **Dise√±o inverso**: Dada C objetivo, encontrar B o SNR necesarios
3. **Comparaci√≥n**: Eficiencia de sistema real vs. l√≠mite de Shannon
4. **An√°lisis de trade-offs**: Costo de duplicar capacidad

### ‚ö†Ô∏è Errores Comunes y Trampas

‚ùå **Error #1: Usar SNR en dB directamente en la f√≥rmula**
- Por qu√© ocurre: Olvido de conversi√≥n
- C√≥mo evitarlo: SIEMPRE convertir dB a lineal primero
- Ejemplo: 20 dB = 100 (no 20) en la f√≥rmula

‚ùå **Error #2: Confundir capacidad con velocidad real**
- Por qu√© ocurre: Shannon da l√≠mite te√≥rico
- C√≥mo evitarlo: Sistemas reales tienen overhead y operan debajo de C
- Realidad: Buenos sistemas alcanzan 50-90% de Shannon

‚ùå **Error #3: Creer que m√°s potencia siempre ayuda proporcionalmente**
- Por qu√© ocurre: Intuici√≥n lineal
- C√≥mo evitarlo: Recordar el logaritmo - rendimientos decrecientes
- A alta SNR: Duplicar potencia solo agrega ~1 bit/s/Hz

### ‚úÖ Puntos Clave para Recordar

#### F√≥rmulas Esenciales
```
Capacidad: C = B log‚ÇÇ(1 + S/N) bits/s
L√≠mite de potencia: C ‚âà 1.44 √ó B √ó (S/N) cuando SNR << 1
L√≠mite de banda: C ‚âà B √ó log‚ÇÇ(SNR) cuando SNR >> 1
Banda infinita: C‚àû = S/(N‚ÇÄ ln 2) = 1.44 S/N‚ÇÄ
```

#### Conceptos Fundamentales
- ‚úì **L√≠mite fundamental**: No hay esquema que supere C
- ‚úì **Trade-off BW-Power**: Recursos intercambiables pero con rendimientos diferentes
- ‚úì **Alcanzable**: Existe codificaci√≥n que se acerca arbitrariamente a C

#### Reglas Mnemot√©cnicas
- üß† **"BLoS"**: Bandwidth, Log, Signal-to-noise
- üß† **Factor 1.44**: Aparece en r√©gimen de baja SNR (1/ln(2))
- üß† **0 dB = transici√≥n**: Cambio entre r√©gimen lineal y logar√≠tmico

#### Valores T√≠picos
| Sistema | BW | SNR | Capacidad | Real | Eficiencia |
|---------|-----|-----|-----------|------|------------|
| DSL | 1.1 MHz | 40 dB | 44 Mbps | 24 Mbps | 55% |
| LTE | 20 MHz | 20 dB | 133 Mbps | 100 Mbps | 75% |
| WiFi 6 | 160 MHz | 35 dB | 1.8 Gbps | 1.2 Gbps | 67% |

### üìö Para Profundizar

#### Recursos Recomendados
- **Paper original**: Shannon, "Communication in the Presence of Noise" (1949)
- **Libro de texto**: Proakis & Salehi, Cap. 7 "Channel Capacity and Coding"
- **Implementaci√≥n**: Simulaciones en MATLAB/Python de curvas de capacidad

#### Temas Relacionados para Explorar
1. Capacidad de canales con desvanecimiento
2. MIMO y capacidad de m√∫ltiples antenas
3. Capacidad con informaci√≥n de estado del canal (CSI)
4. Teor√≠a de tasa-distorsi√≥n

#### Preguntas para Reflexionar
- ¬øPor qu√© el logaritmo aparece naturalmente en la capacidad?
- ¬øQu√© pasar√≠a si el ruido no fuera gaussiano?
- ¬øC√≥mo cambiar√≠a todo si pudi√©ramos usar retroalimentaci√≥n?

---

## üè∑Ô∏è Metadatos de la Carta

**Dificultad**: ‚≠ê‚≠ê‚≠ê‚≠ê (4/5 estrellas)
**Tiempo de estudio sugerido**: 60 minutos
**Prerequisitos cr√≠ticos**: Entrop√≠a, procesos gaussianos, teor√≠a de informaci√≥n
**Tags**: `#shannon` `#capacidad-canal` `#limite-fundamental` `#awgn`

---

*Generado el: 2024-11-16*
*√öltima revisi√≥n: 2024-11-16*